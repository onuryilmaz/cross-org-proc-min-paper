\section{Results and Discussions}
\label{sec:results-and-discussions}

In this section, methodology presented in this study is applied on datasets and results are presented. Firstly, evaluation metrics are defined for each stage of methodology to assess the performance of approach. Following this, methodology is applied on two datasets and results are explained with discussions.

Approach in this study is an aggregation of various methods and they are significantly different from each other in their mathematical background. Therefore, instead of a global evaluation metric for the complete methodology, each stage is evaluated within its evaluation metrics which are as follows:
\begin{description}
	\item[Process Model Mining] Performance of process mining stage is measured by \textit{fitness} and \textit{appropriateness} which are defined in \cite{rozinat2008conformance}.
	\item[Performance Indicator Analysis] In replay phase, \textit{alignment costs} \cite{van2012replaying} are compared with process model mining metrics. In clustering phase, \textit{within-SSE} analysis is undertaken to decide on the number of clusters.
	\item[Mismatch Pattern Analysis] In this stage, number of mismatch patterns found are compared with the \textit{graph-edit similarity} \cite{dijkman2011similarity} of process models.
	\item[Recommendation Generation] In recommendation generation, different threshold values are tried to check how many mismatch patterns are generated for organizations and how they could be used for focused analysis.
\end{description}

\input{5_results_discussions/loan-application-process/loan-application-process.tex}
\input{5_results_discussions/coselog-wabo/coselog-wabo.tex}

\subsection{Discussions}
\label{subsec:discussions}
When the evaluation of the stages for \textit{Loan Application Process} and \textit{Environmental Permit Application Process} datasets are gathered together, the following results can be expressed:

\begin{itemize}
	\item Process mining stage of the proposed methodology can mine the process models with high fitness appropriateness levels.
	\item For the successfully mined models with high fitness values, replay and performance indicator calculation stage works seamlessly as expected. With this step, average and standard deviation time between each activity can be measured for each organization. Number of these metrics are quadratic to the number of activities in each organization's process model and difficult to analyze with a cross comparison.
	\item Internal measure of clusters indicates that the organizations can be clustered according to their performance indicators which yields a collective approach of organizations for their subprocesses. In other words, organizations are divided into clusters which shows that they can be grouped based on how well they are executing.
	\item Mismatch analysis spots the differences between process models in coherence with structural similarity of them. This indicates that the idea of using mismatch patterns to reveal differences between process models is a feasible approach since its results are comparable to the similarity metrics of process models in the literature.
	\item Recommendation generation aims to gather all generated information in this study to help focusing on the potentially important mismatch patterns for performance improvement. When the number of mismatch patterns with and without performance clusterings are checked, it shows that in a small dataset performance clustering lists 3 times less number of differences in \textit{Loan Application Example} dataset. When it is impossible to locate mismatch patterns manually like in \textit{Environmental Permit Application Process}, performance clustering spots 100 times less number of differences. This difference helps user to focus on the differences with a potential performance improvement which is one of the aims in this thesis study.
	\item Although each step of methodology can be counted as successful based on their evaluation metrics, mismatch patterns recommended at the end of methodology can yield important observations as well as being irrelevant and infeasible. Since this decision is based on the business environment of organizations, evaluation of the quality of recommendations for business usefulness requires domain expertise. However, an example recommendation can be presented to provide an insight. In the analysis of \textit{Loan Application Process}, Variant \#3 performs worse 27 \%  on average time and 12 \% on standard deviation time between activities "Calculate Capacity" and "Accept". When the mismatch patterns for these performance indicators are checked the following ones can be mentioned:
		\begin{itemize}
		\item "Check Credit" is a \textit{Refined Activity} of with "Check System (50 \%)"; "Check Paper Archive (42 \%)"; "Send Credit Check Request (32 \%)"; "Process Credit Check Reply (31 \%)" where the corresponding similarity values provided in parentheses.
		\item "Calculate Capacity" is a \textit{Different Moments in Processes} which have different previous activities in clusters. 
		\end{itemize}
	When these example mismatch patterns are checked, removing "Check Credit" activity and putting other activities instead of it might be the cause of performance improvement. With the same approach, putting "Calculate Capacity" on different orders in processes can effect the average and variance of time between activities. These mismatch patterns are also visualized on process model of Variant \#3 and a variant from other cluster in Figure~\ref{fig:loan-recommendation-visualization}. In the process models, refined activities of "Check Credit" and different positions of "Calculate Capacity" are indicated. 
		\begin{figure}
			\centering
			\includegraphics[width=\textwidth]{5_results_discussions/loan-application-process/recommendation-visualization}
			\caption{Visualization of example recommendation for Loan Application Process dataset}
		  \label{fig:loan-recommendation-visualization}
		\end{figure}
\end{itemize} % end of discussions